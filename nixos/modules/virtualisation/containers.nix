{ config, lib, pkgs, ... }:
let
  cfg = config.virtualisation.containers;

  inherit (lib) literalExpression mkOption types;

  cdiGenerators = [ "nvidia-ctk-generate" ];

  isCDIAutoGenerated = cdi:
    builtins.isString cdi && builtins.elem cdi cdiGenerators;

  json = pkgs.formats.json { };
  toml = pkgs.formats.toml { };
in
{
  meta = {
    maintainers = [ ] ++ lib.teams.podman.members;
  };

  options.virtualisation.containers = {

    enable =
      mkOption {
        type = types.bool;
        default = false;
        description = lib.mdDoc ''
          This option enables the common /etc/containers configuration module.
        '';
      };

    ociSeccompBpfHook.enable = mkOption {
      type = types.bool;
      default = false;
      description = lib.mdDoc "Enable the OCI seccomp BPF hook";
    };

    cdi = mkOption {
      type = types.attrsOf (types.either (types.enum cdiGenerators) json.type);
      default = { };
      description = lib.mdDoc ''
        This option configures the Container Device Interface (CDI) of the system. Every key of the attribute set will be mapped to a file in /etc/cdi, and is required to be provided in JSON format.
      '';
      example = literalExpression ''
        {
          nvidia = builtins.fromJSON '''
            {
              "cdiVersion": "0.5.0",
              "kind": "nvidia.com/gpu",
              "devices": [ ... ],
              "containerEdits": { ... }
            }
          ''';
        }
      '';
    };

    containersConf.settings = mkOption {
      type = toml.type;
      default = { };
      description = lib.mdDoc "containers.conf configuration";
    };

    containersConf.cniPlugins = mkOption {
      type = types.listOf types.package;
      defaultText = literalExpression ''
        [
          pkgs.cni-plugins
        ]
      '';
      example = literalExpression ''
        [
          pkgs.cniPlugins.dnsname
        ]
      '';
      description = lib.mdDoc ''
        CNI plugins to install on the system.
      '';
    };

    storage.settings = mkOption {
      type = toml.type;
      default = {
        storage = {
          driver = "overlay";
          graphroot = "/var/lib/containers/storage";
          runroot = "/run/containers/storage";
        };
      };
      description = lib.mdDoc "storage.conf configuration";
    };

    registries = {
      search = mkOption {
        type = types.listOf types.str;
        default = [ "docker.io" "quay.io" ];
        description = lib.mdDoc ''
          List of repositories to search.
        '';
      };

      insecure = mkOption {
        default = [ ];
        type = types.listOf types.str;
        description = lib.mdDoc ''
          List of insecure repositories.
        '';
      };

      block = mkOption {
        default = [ ];
        type = types.listOf types.str;
        description = lib.mdDoc ''
          List of blocked repositories.
        '';
      };
    };

    policy = mkOption {
      default = { };
      type = types.attrs;
      example = literalExpression ''
        {
          default = [ { type = "insecureAcceptAnything"; } ];
          transports = {
            docker-daemon = {
              "" = [ { type = "insecureAcceptAnything"; } ];
            };
          };
        }
      '';
      description = lib.mdDoc ''
        Signature verification policy file.
        If this option is empty the default policy file from
        `skopeo` will be used.
      '';
    };

  };

  config = lib.mkIf cfg.enable {

    virtualisation.containers.containersConf.cniPlugins = [ pkgs.cni-plugins ];

    virtualisation.containers.containersConf.settings = {
      network.cni_plugin_dirs = map (p: "${lib.getBin p}/bin") cfg.containersConf.cniPlugins;
      engine = {
        init_path = "${pkgs.catatonit}/bin/catatonit";
      } // lib.optionalAttrs cfg.ociSeccompBpfHook.enable {
        hooks_dir = [ config.boot.kernelPackages.oci-seccomp-bpf-hook ];
      };
    };

    environment.etc = let
      cdiConfigurationFiles = let
        cdiSpecs = lib.attrsets.filterAttrs
          (name: value: (builtins.isAttrs value) && (builtins.hasAttr "cdiVersion" value)) cfg.cdi;
      in (lib.attrsets.mapAttrs'
        (name: value:
          lib.attrsets.nameValuePair (builtins.concatStringsSep "/" ["cdi" (name + ".json")])
            { text = builtins.toJSON value; })
        cdiSpecs);
    in {
      "containers/containers.conf".source =
        toml.generate "containers.conf" cfg.containersConf.settings;

      "containers/storage.conf".source =
        toml.generate "storage.conf" cfg.storage.settings;

      "containers/registries.conf".source = toml.generate "registries.conf" {
        registries = lib.mapAttrs (n: v: { registries = v; }) cfg.registries;
      };

      "containers/policy.json".source =
        if cfg.policy != { } then pkgs.writeText "policy.json" (builtins.toJSON cfg.policy)
        else "${pkgs.skopeo.policy}/default-policy.json";
    } // cdiConfigurationFiles;

    systemd.services = let
      cdiAutoGenerated = lib.attrsets.filterAttrs
        (name: value: (
          lib.throwIf (builtins.isString value && !builtins.elem value cdiGenerators)
            "CDI is configured to be auto-generated for ${name}, but generator ${value} is not identified. The list of well-known auto-generators is: ${lib.strings.concatStrings (lib.strings.intersperse ", " cdiGenerators)}"
            (isCDIAutoGenerated value)
        )) cfg.cdi;
    in lib.attrsets.mapAttrs'
      (name: value:
        (if value == "nvidia-ctk-generate" then
          lib.attrsets.nameValuePair (name + "-cdi-generator") ({
            description = "CDI for Nvidia generator";
            wantedBy = [ "multi-user.target" ];
            after = [ "systemd-udev-settle.service" ];
            serviceConfig = {
              ExecStart = pkgs.writeScript (name + "cdi-generator") ''
                #! ${pkgs.runtimeShell}
                umask 0133
                ${pkgs.nvidia-podman}/bin/nvidia-ctk cdi generate \
                  --format json \
                  --ldconfig-path ${pkgs.glibc.bin}/bin/ldconfig \
                  --library-search-path ${pkgs.linuxPackages.nvidia_x11}/lib \
                  --nvidia-ctk-path ${pkgs.nvidia-podman}/bin/nvidia-ctk | \
                ${pkgs.jq}/bin/jq \
                  '.containerEdits.hooks[].args |= map(if . == "${pkgs.linuxPackages.nvidia_x11}/lib" then . = "/usr/lib" end)' | \
                ${pkgs.jq}/bin/jq \
                  '.containerEdits.hooks[].args |= map(if . == "${pkgs.linuxPackages.nvidia_x11}/lib" then . = "/usr/lib" end)' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "${pkgs.linuxPackages.nvidia_x11}/lib/libcuda.so", "containerPath": "/usr/lib/libcuda.so", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "${pkgs.linuxPackages.nvidia_x11}/lib/libcuda.so.1", "containerPath": "/usr/lib/libcuda.so.1", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/run/current-system/sw/bin/nvidia-cuda-mps-control", "containerPath": "/usr/bin/nvidia-cuda-mps-control", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/run/current-system/sw/bin/nvidia-cuda-mps-server", "containerPath": "/usr/bin/nvidia-cuda-mps-server", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/run/current-system/sw/bin/nvidia-debugdump", "containerPath": "/usr/bin/nvidia-debugdump", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/run/current-system/sw/bin/nvidia-powerd", "containerPath": "/usr/bin/nvidia-powerd", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/run/current-system/sw/bin/nvidia-smi", "containerPath": "/usr/bin/nvidia-smi", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "/nix/store", "containerPath": "/nix/store", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                   '.containerEdits.mounts[.containerEdits.mounts | length] |= . + { "hostPath": "${pkgs.nvidia-podman}/bin/nvidia-ctk", "containerPath": "/usr/bin/nvidia-ctk", "options": ["ro", "nosuid", "nodev", "bind"] }' | \
                ${pkgs.jq}/bin/jq \
                  '.containerEdits.mounts[].containerPath |= sub("/run/current-system/sw/bin"; "/usr/bin")' | \
                ${pkgs.jq}/bin/jq \
                  '.containerEdits.mounts[].containerPath |= sub("${pkgs.linuxPackages.nvidia_x11}/lib"; "/usr/lib")' \
                   > /etc/cdi/${name}.json
            '';
            };
          })
         else
           throw "Unknown CDI specification generator: ${value}"
        )) cdiAutoGenerated;

  };

}
